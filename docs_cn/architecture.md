# ModularBase - 模块化基座模型架构设计

## 一、核心理念

将大模型拆解为 **"极简基座 + 可插拔数据包"** 的模块化架构：
- 基座只负责理解和调度，不存储领域知识
- 知识和能力封装在独立的数据包中
- 数据包可共享、可增量训练、按需加载
- 上下文压缩缓存到虚拟内存，支持超长上下文

## 二、核心设计决策

| 问题 | 决策 |
|------|------|
| 数据包形式 | **独立小网络**，不是LoRA叠加 |
| 基座来源 | **从零训练**专用基座 |
| 数据包本质 | 领域知识压缩成权重 + 专家网络 |
| 上下文管理 | 压缩后缓存到虚拟内存(磁盘) |
| 实现语言 | **混合**: Python训练 + C++推理 |
| 训练方式 | **标准PyTorch**，兼容现有生态 |

## 2.1 混合实现架构

```
┌─────────────────────────────────────────────────────────────────┐
│                        Python层 (训练 + 高层逻辑)                │
│  - PyTorch模型定义                                              │
│  - 训练循环、优化器                                              │
│  - 包调度逻辑                                                   │
│  - API接口                                                      │
├─────────────────────────────────────────────────────────────────┤
│                        C++层 (推理 + 性能关键)                   │
│  - Attention计算 (CUDA加速)                                     │
│  - 矩阵运算 (cuBLAS)                                            │
│  - KV Cache压缩/解压                                            │
│  - 数据包加载/卸载                                               │
│  - 内存管理                                                     │
└─────────────────────────────────────────────────────────────────┘
```

**为什么这样设计：**
- 训练用PyTorch：兼容现有工具(wandb、tensorboard)、可用预训练权重
- 推理用C++：性能最大化，减少Python开销
- 权重格式统一：训练完导出，C++推理加载

## 三、架构总览

```
┌─────────────────────────────────────────────────────────────────┐
│                     常驻部分 (不可卸载)                          │
│  ┌───────────────────────────────────────────────────────────┐  │
│  │                    基座核心 (~0.3B)                        │  │
│  │     Embedding │ 上下文管理 │ 包调度器 │ 输出解码           │  │
│  └───────────────────────────────────────────────────────────┘  │
│                                                                  │
│  ┌──────────────┐                    ┌──────────────┐           │
│  │   路由包     │                    │ 通用对话包   │           │
│  │   ~0.2B     │                    │   ~0.3B      │           │
│  │  (不可删除)  │                    │  (不可删除)  │           │
│  └──────────────┘                    └──────────────┘           │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼ 按需加载
┌─────────────────────────────────────────────────────────────────┐
│                       按需加载包 (可插拔)                        │
│  ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐       │
│  │推理引擎│ │Python  │ │ 医疗   │ │ 法律   │ │ 创意   │  ...  │
│  │  包    │ │代码包  │ │问答包  │ │咨询包  │ │写作包  │       │
│  │(系统包)│ │(领域包)│ │(领域包)│ │(领域包)│ │(领域包)│       │
│  └────────┘ └────────┘ └────────┘ └────────┘ └────────┘       │
└─────────────────────────────────────────────────────────────────┘
```

## 四、架构详细设计

### 4.1 整体数据流

```
用户输入
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│                         基座核心                                 │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐       │
│  │Embedding│ -> │ 理解层  │ -> │ 调度器   │ -> │ 融合层   │       │
│  └─────────┘    └─────────┘    └────┬────┘    └────┬────┘       │
└────────────────────────────────────│──────────────│─────────────┘
                                     │              │
                    ┌────────────────┘              │
                    ▼                               │
┌─────────────────────────────────────┐             │
│            路由包 (常驻)             │             │
│  分析意图 -> 选择数据包               │             │
└─────────────────────────────────────┘             │
                    │                               │
                    ▼                               │
┌─────────────────────────────────────┐            │
│         选中的数据包 (独立网络)       │ ──────────┘
│  ┌──────┐  ┌──────┐  ┌──────┐      │
│  │通用包│  │推理包│  │领域包│      │
│  └──────┘  └──────┘  └──────┘      │
└─────────────────────────────────────┘
                    │
                    ▼
               输出结果
```

### 4.2 基座核心设计

基座是极简的，只做**理解**和**调度**：

```
基座核心 (~0.5B)
├── Embedding层 (共享，所有包复用)
│   └── 词表: 32K-64K
│   └── 维度: 1024
│
├── 理解层 (4-6层Transformer)
│   └── 理解输入语义
│   └── 生成hidden state给数据包
│
├── 调度器
│   └── 接收路由包的决策
│   └── 管理包的加载/卸载
│
└── 融合层 (2层)
    └── 合并多个包的输出
    └── 生成最终输出
```

### 4.3 数据包设计 (独立小网络)

每个数据包是**独立的小型Transformer网络**：

```
数据包结构 (~0.1-0.3B)
├── 输入适配层
│   └── 接收基座的hidden state
│
├── 专家层 (4-8层Transformer)
│   └── 领域知识编码在这里
│   └── 独立的attention和FFN
│
└── 输出适配层
    └── 输出给基座融合层
```

**数据包类型：**

| 类型 | 名称 | 大小 | 说明 |
|------|------|------|------|
| 常驻 | 路由包 | ~0.1B | 分析意图，选择包 |
| 常驻 | 通用对话包 | ~0.2B | 闲聊、常识 |
| 按需 | 推理引擎包 | ~0.2B | 逻辑、数学 |
| 按需 | 领域包 | ~0.1-0.2B | Python/医疗/法律... |

### 4.4 上下文压缩缓存

**核心思路**：把已处理的上下文压缩后存到虚拟内存(磁盘)，需要时再加载

```
┌─────────────────────────────────────────────────────────────────┐
│                        上下文管理                                │
│                                                                  │
│   GPU显存 (热区)              虚拟内存/磁盘 (冷区)               │
│  ┌─────────────────┐        ┌─────────────────────────┐        │
│  │ 当前对话窗口    │        │ 压缩的历史上下文         │        │
│  │ (最近2K tokens) │  <-->  │ (可达100K+ tokens)      │        │
│  │ 完整精度        │        │ 量化压缩存储            │        │
│  └─────────────────┘        └─────────────────────────┘        │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

**压缩策略：**
1. KV Cache压缩：把attention的KV cache量化(FP16->INT8)
2. 摘要压缩：旧对话生成摘要embedding
3. 分层存储：重要的保留完整，不重要的只保留摘要

## 五、多包协作机制

当需要多个包同时工作时：

```
输入: "用Python写个快速排序，解释一下原理"
                │
                ▼
路由包判断: 需要 [通用对话包 + Python包 + 推理包]
                │
        ┌───────┼───────┐
        ▼       ▼       ▼
    ┌──────┐┌──────┐┌──────┐
    │通用包││Python││推理包│  <- 并行处理
    └──┬───┘└──┬───┘└──┬───┘
       │       │       │
       └───────┼───────┘
               ▼
         融合层合并
               │
               ▼
            输出
```

**融合策略：**
- 加权平均：根据路由包给的置信度加权
- Attention融合：让各包输出互相attend
- 主从模式：一个主包，其他包辅助

## 六、训练方案

### 6.1 训练框架选择

**使用标准PyTorch训练**，兼容现有生态：

```
训练阶段 (PyTorch)              推理阶段 (C++)
┌─────────────────┐            ┌─────────────────┐
│ - torch.nn      │            │ - 自研C++引擎   │
│ - AdamW优化器   │  导出权重   │ - CUDA加速      │
│ - DataLoader    │ ────────> │ - 量化推理      │
│ - wandb监控     │            │ - 内存优化      │
└─────────────────┘            └─────────────────┘
```

### 6.2 训练阶段

```
阶段1: 训练基座核心
  └── 大规模通用语料
  └── 目标: 语言理解能力

阶段2: 训练路由包
  └── 意图分类数据集
  └── 目标: 准确识别需要哪些包

阶段3: 训练通用对话包
  └── 对话数据集
  └── 目标: 基础对话能力

阶段4: 训练领域包 (可并行)
  └── 各领域专业数据
  └── 目标: 领域专家能力
```

### 6.3 数据包训练 (独立网络)

```python
# 训练单个数据包
def train_pack(pack, domain_data):
    # 冻结基座，只训练包
    base.freeze()
    
    for batch in domain_data:
        # 基座提供hidden state
        hidden = base.encode(batch.input)
        
        # 包处理
        pack_output = pack(hidden)
        
        # 基座融合输出
        output = base.fuse_and_decode(pack_output)
        
        # 计算loss，更新包参数
        loss = criterion(output, batch.target)
        loss.backward()
        pack.optimizer.step()
```

### 6.4 增量训练 (新数据归类)

```
新数据进来
    │
    ▼
路由包分析 -> 属于哪个领域？
    │
    ├─→ 已有包 -> 增量训练该包 (不影响其他包)
    │
    └─→ 新领域 -> 创建新数据包 -> 训练
```

## 七、显存与存储分配

### 7.1 显存分配 (4GB显卡)

| 组件 | 显存 | 说明 |
|------|------|------|
| 基座核心 | ~1.0GB | 常驻 |
| 路由包 | ~0.2GB | 常驻 |
| 通用对话包 | ~0.4GB | 常驻 |
| **常驻总计** | **~1.6GB** | |
| 按需包槽位 | ~0.6GB | 最多2-3个包 |
| 当前上下文 | ~0.5GB | 热区KV Cache |
| 计算缓冲 | ~0.3GB | |
| **总计** | **~3.0GB** | 留1GB余量 |

### 7.2 虚拟内存/磁盘

| 内容 | 大小 | 说明 |
|------|------|------|
| 压缩历史上下文 | 可变 | 支持100K+ tokens |
| 未加载的数据包 | ~0.2GB/个 | 按需加载 |
| KV Cache溢出 | 可变 | 超长对话时 |

## 八、数据包文件格式

```
pack_python_v1.0/
├── manifest.json       # 元信息
├── model.bin           # 独立网络权重
├── tokenizer/          # 如果有专用词表
└── examples.json       # few-shot示例
```

**manifest.json:**
```json
{
  "id": "python_code",
  "name": "Python代码包",
  "version": "1.0.0",
  "type": "domain",
  "size_mb": 200,
  "layers": 6,
  "hidden_size": 1024,
  "keywords": ["python", "代码", "编程"],
  "dependencies": []
}
```

## 九、与传统架构对比

| 特性 | 传统大模型 | ModularBase |
|------|------------|-------------|
| 知识存储 | 全在一个网络 | 分散在独立包 |
| 更新方式 | 全量微调 | 只更新相关包 |
| 显存占用 | 固定 | 动态按需 |
| 上下文长度 | 受限于显存 | 可压缩到磁盘 |
| 能力扩展 | 重新训练 | 添加新包 |
| 遗忘问题 | 严重 | 包隔离不影响 |

---

**项目代号**: ModularBase  
**目标**: 极简基座 + 独立数据包 + 压缩上下文，在4GB显卡上实现模块化AI
