# CardInfer 目标规划

## 一、项目目标

让消费级显卡越级运行更大参数的模型，通过串行流式推理技术突破显存限制。

## 二、显卡适配目标

### 2.1 常规越级（推荐，速度优先）

| 显存 | 代表显卡 | 正常能跑 | 越级目标 | 量化精度 | 预期速度 |
|------|----------|----------|----------|----------|----------|
| 2GB | GTX 1050 | 0.5B | **4B** | Q2_K | 2-3 tok/s |
| 4GB | GTX 1650 | 1-2B | **7B-14B** | Q2_K | 3-5 tok/s |
| 6GB | GTX 1660 | 3-4B | **14B-20B** | Q3_K | 5-8 tok/s |
| 8GB | RTX 3060 | 7B | **27B-34B** | Q4_K | 8-12 tok/s |
| 12GB | RTX 4070 | 14B | **34B-70B** | Q4_K | 10-15 tok/s |
| 16GB | RTX 4080 | 20B | **70B-120B** | Q4_K | 12-18 tok/s |
| 24GB | RTX 4090 | 34B | **120B-235B** | Q4_K | 15-20 tok/s |

### 2.2 极限越级（慢速模式）

| 显存 | 代表显卡 | 极限越级 | 量化精度 | 预期速度 |
|------|----------|----------|----------|----------|
| 2GB | GTX 1050 | **14B** | Q1_K | 0.5-1 tok/s |
| 4GB | GTX 1650 | **20B-27B** | Q2_K | 1-2 tok/s |
| 8GB | RTX 3060 | **70B** | Q3_K | 3-5 tok/s |
| 24GB | RTX 4090 | **480B** | Q4_K | 10-15 tok/s |

## 三、核心技术指标

### 3.1 显存控制
- 显存峰值不超过显卡容量的 **80%**
- 单层权重 + 激活值 + KV Cache 总和控制在限制内

### 3.2 推理速度
- 最低可用速度：**3 tok/s**
- 目标速度：比完整加载慢 **2-3倍**，但仍可接受

### 3.3 推理质量
- 与完整加载推理 **无质量损失**
- 所有层都参与计算，只是分批加载

## 四、技术方案

### 4.1 串行流式推理
```
输入 → Embedding(加载→计算→卸载) 
     → Layer0(加载→计算→卸载) 
     → Layer1(加载→计算→卸载) 
     → ... 
     → LayerN(加载→计算→卸载) 
     → LM_Head(加载→计算→卸载) 
     → 输出
```

### 4.2 显存占用分析（以14B Q4为例）
- 单层权重：~200MB
- 激活值：~50MB
- KV Cache：~100MB（可卸载到内存）
- **总计：~350MB**（远小于6GB限制）

## 五、MVP验收标准

### 功能验收
- [ ] Qwen3-4B模型切片成功
- [ ] 串行流式推理跑通
- [ ] 输出结果与Ollama一致

### 性能验收
- [ ] 显存峰值 < 500MB
- [ ] 推理速度 > 3 tok/s
- [ ] 无OOM崩溃

### 质量验收
- [ ] 输出文本语义正确
- [ ] 无乱码/截断
- [ ] 多轮对话正常

## 六、成功标准

**6GB显卡成功运行14B模型，速度5+ tok/s，质量无损失。**
