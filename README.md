# ModularBase

**Minimal Base + Pluggable Data Packs** â€” Run Professional AI on 4GB GPUs

[![Status](https://img.shields.io/badge/Status-Active%20Development-blue)]()
[![License](https://img.shields.io/badge/License-Apache%202.0-green)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-blue)]()
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange)]()

---

## ðŸŽ¯ Vision

Current LLM challenges:
- 7B models require 14GB+ VRAM, out of reach for most users
- Adding new capabilities requires full retraining, expensive
- Knowledge updates cause catastrophic forgetting

**ModularBase's Solution**: Decompose LLMs into "Minimal Base + Pluggable Data Packs"

```
Traditional LLM:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 7B params, monolithic

ModularBase:      [Base 0.5B] + [Router] + [Chat] + [Code] + [Medical] + ...
                       â†‘           â†‘         â†‘         â†‘          â†‘
                   Resident    Resident  Resident  On-demand  On-demand
```

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| **Ultra-low VRAM** | Runs smoothly on 4GB GPUs, ~1.6GB resident |
| **Modular Capabilities** | Data packs train and update independently |
| **On-demand Loading** | Only load packs needed for current task |
| **No Forgetting** | New capabilities don't affect existing ones |
| **Easy Extension** | Add new domains by training new data packs |

## ðŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Resident (~1.6GB)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Base Core (Understanding + Routing + Fusion) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Router Pack â”‚              â”‚ General Chat â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼ On-demand Loading
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Code  â”‚ â”‚Reasoningâ”‚ â”‚Medical â”‚ â”‚ Legal  â”‚ â”‚Creativeâ”‚   â”‚
â”‚  â”‚  Pack  â”‚ â”‚  Pack   â”‚ â”‚  Pack  â”‚ â”‚  Pack  â”‚ â”‚  Pack  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“Š VRAM Comparison

| Solution | VRAM Required | Capability Extension | Update Cost |
|----------|---------------|---------------------|-------------|
| Llama-7B | 14GB+ | Full retrain | High |
| Qwen-1.8B | 4GB | Full retrain | Medium |
| **ModularBase** | **~2-3GB** | **Add data packs** | **Low** |

## ðŸš€ Quick Start

```bash
# Clone the project
git clone https://github.com/your-username/ModularBase.git
cd ModularBase

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or .\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Download training data
python scripts/download_data.py

# Train base model
python scripts/train_base.py

# Train data packs
python scripts/train_packs.py

# Test inference
python scripts/test_inference.py
```

## ðŸ“ Project Structure

```
ModularBase/
â”œâ”€â”€ docs_cn/                    # Chinese documentation
â”œâ”€â”€ modular_base/               # Core implementation
â”‚   â”œâ”€â”€ model/                  # Model definitions (base, packs, router)
â”‚   â”œâ”€â”€ engine/                 # Inference engine (pack manager, context compression)
â”‚   â””â”€â”€ training/               # Training utilities
â”œâ”€â”€ packs/                      # Trained data packs
â”œâ”€â”€ data/                       # Training data

```

## ðŸ—ºï¸ Roadmap

### Phase 1: Architecture Validation âœ…
- [x] Core architecture design
- [x] Base + Data Pack + Router implementation
- [x] Inference engine prototype
- [x] Small-scale training validation

### Phase 2: Model Training ðŸš§ In Progress
- [ ] Large-scale data training (50K-200K)
- [ ] Base model optimization
- [ ] Core data pack training

### Phase 3: Performance Optimization
- [ ] INT8/INT4 quantization
- [ ] KV Cache compression
- [ ] C++ inference engine

### Phase 4: Ecosystem Building
- [ ] Data pack development tools
- [ ] Data pack marketplace
- [ ] Community contribution guide

## ðŸ“– Documentation

| Document | Description |
|----------|-------------|
| [Architecture](architecture.md) | Core architecture and design decisions |
| [Optimization](optimization.md) | Performance, engineering, robustness optimization |
| [Progress](progress.md) | Current status and next steps |
| [CardInfer](cardinfer.md) | Serial streaming inference engine |
| [Roadmap](roadmap.md) | Development roadmap |
| [Contributing](contributing.md) | How to contribute |

## ðŸ¤ Contributing

The project is in early development. Welcome to:
- ðŸŒŸ Star to follow progress
- ðŸ’¡ Discuss architecture in Issues
- ðŸ”§ Contribute code via PR

See [Contributing Guide](contributing.md)

## ðŸ“„ License

Apache 2.0

---

> **"The future of AI shouldn't belong only to those with top-tier hardware"**


